{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('target_embedding_layer.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52905864,  0.2682494 ,  0.08240538,  0.6040402 , -0.40000755,\n",
       "        0.40325102,  0.47333264,  0.12564887,  0.20180437, -0.14357038,\n",
       "       -0.5900948 ,  0.31010377,  0.47124326, -0.28503367,  0.23567382,\n",
       "        0.38805783, -0.00675848,  0.6721102 ,  0.24879739,  0.1021815 ,\n",
       "        0.4804473 ,  0.5193118 , -0.13982862,  0.26506346,  0.20593485,\n",
       "        0.03859131,  0.13175163, -0.43383372,  0.4473232 , -0.0037769 ,\n",
       "       -0.25819823, -0.13163319,  0.5636755 , -0.3039646 ,  0.2620538 ,\n",
       "        0.17377025,  0.2168366 ,  0.5943611 , -0.12959692,  0.42138287,\n",
       "        0.08954721, -0.37473172, -0.26947808,  0.04299825,  0.08381032,\n",
       "       -0.11034341,  0.13256617, -0.09809101,  0.4045905 ,  0.19616552],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('series', 0.8369984030723572),\n",
       " ('one', 0.8337945342063904),\n",
       " ('novel', 0.7874147891998291),\n",
       " ('author', 0.7279027700424194),\n",
       " ('review', 0.7255702018737793),\n",
       " ('item', 0.725570023059845),\n",
       " ('story', 0.721172034740448),\n",
       " ('disappointed', 0.7175264358520508),\n",
       " ('price', 0.7053964138031006),\n",
       " ('ending', 0.692419171333313)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.7873197793960571),\n",
       " ('course', 0.7200912237167358),\n",
       " ('husband', 0.6906254291534424),\n",
       " ('money', 0.6792412400245667),\n",
       " ('interest', 0.6782873272895813),\n",
       " ('10', 0.6774787306785583),\n",
       " ('liking', 0.6729978322982788),\n",
       " ('structure', 0.6718193888664246),\n",
       " ('friends', 0.6632583737373352),\n",
       " ('kids', 0.6596392393112183)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"son\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('events', 0.7585431933403015),\n",
       " ('part', 0.7572298049926758),\n",
       " ('last', 0.7551019191741943),\n",
       " ('period', 0.7526201009750366),\n",
       " ('beginning', 0.7491883635520935),\n",
       " ('perspective', 0.7470282912254333),\n",
       " ('premise', 0.7447119355201721),\n",
       " ('level', 0.7434907555580139),\n",
       " ('mystery', 0.7425572872161865),\n",
       " ('point', 0.7388588786125183)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recipes', 0.7460935711860657),\n",
       " ('men', 0.7343083620071411),\n",
       " ('rest', 0.7195408940315247),\n",
       " ('works', 0.7159797549247742),\n",
       " ('students', 0.7137537598609924),\n",
       " ('spent', 0.7058455348014832),\n",
       " ('editing', 0.7005631327629089),\n",
       " ('ways', 0.6965265870094299),\n",
       " ('inside', 0.6964934468269348),\n",
       " ('attempts', 0.6962164044380188)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"hand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', 0.7640765309333801),\n",
       " ('era', 0.7042155861854553),\n",
       " ('fault', 0.7006778717041016),\n",
       " ('game', 0.7000216245651245),\n",
       " ('while', 0.6908008456230164),\n",
       " ('copy', 0.6753082871437073),\n",
       " ('home', 0.6675803661346436),\n",
       " ('collection', 0.6673161387443542),\n",
       " ('heart', 0.6661427617073059),\n",
       " ('inside', 0.6577143669128418)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pretentious', 0.5812702178955078),\n",
       " ('drawn', 0.5461557507514954),\n",
       " ('subtle', 0.5405817031860352),\n",
       " ('dictated', 0.532189130783081),\n",
       " ('shameless', 0.5273035168647766),\n",
       " ('denial', 0.524050235748291),\n",
       " ('engage', 0.5140932202339172),\n",
       " ('outdated', 0.5114582777023315),\n",
       " ('language', 0.49841275811195374),\n",
       " ('Underwood', 0.4966738522052765)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.9033777713775635),\n",
       " ('nice', 0.8178068995475769),\n",
       " ('decent', 0.8010609745979309),\n",
       " ('funny', 0.797417163848877),\n",
       " ('short', 0.7970183491706848),\n",
       " ('fun', 0.788172721862793),\n",
       " ('useful', 0.7870458960533142),\n",
       " ('interesting', 0.785613477230072),\n",
       " ('informative', 0.7841373682022095),\n",
       " ('enjoyable', 0.7671247124671936)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exciting', 0.7636231780052185),\n",
       " ('funny', 0.7555890083312988),\n",
       " ('good', 0.7522293329238892),\n",
       " ('simple', 0.7427698969841003),\n",
       " ('print', 0.7367860674858093),\n",
       " ('short', 0.7334396839141846),\n",
       " ('far', 0.7321767807006836),\n",
       " ('overall', 0.7297816872596741),\n",
       " ('movie', 0.7254855036735535),\n",
       " ('rushed', 0.723323404788971)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mattie', 0.6132054328918457),\n",
       " ('sucker', 0.5414050817489624),\n",
       " ('Inuit', 0.5228683352470398),\n",
       " ('by', 0.5099499821662903),\n",
       " ('cheesey', 0.5028645396232605),\n",
       " ('themes', 0.48187267780303955),\n",
       " ('homemade', 0.4800800681114197),\n",
       " ('overlay', 0.478593647480011),\n",
       " ('codependent', 0.477465957403183),\n",
       " ('Reeman', 0.4762853682041168)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"humanistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('endure', 0.589384138584137),\n",
       " ('Force', 0.534084677696228),\n",
       " ('Serial', 0.5203403830528259),\n",
       " ('Nature', 0.5045533776283264),\n",
       " ('uk', 0.5043767094612122),\n",
       " ('Plenty', 0.4930706322193146),\n",
       " ('relato', 0.49204447865486145),\n",
       " ('Chief', 0.4882318079471588),\n",
       " ('rhythms', 0.48484084010124207),\n",
       " ('ultrasound', 0.48478803038597107)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"encyclopedia\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training result seems to be different according to different target words chosen. I suspect that this is due to the size of the training data for each target word."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'narcissistic'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('hostility', 'goodwill', 'enemy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'portray'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('sweet', 'truth', 'dream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'real'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('fake', 'true', 'history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'century'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('moon', 'warmth', 'sun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SI630_hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "21c5b6f17d70f902198b1e3f6d05b43fc7fe8322a3048219c11047544967500b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
